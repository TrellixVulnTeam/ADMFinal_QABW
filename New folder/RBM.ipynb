{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\saura\\Recommenders\n"
     ]
    }
   ],
   "source": [
    "cd C:\\Users\\saura\\Recommenders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "conda activate reco_base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow==1.15.3 in c:\\users\\saura\\anaconda3\\lib\\site-packages (1.15.3)\n",
      "Requirement already satisfied: wrapt>=1.11.1 in c:\\users\\saura\\anaconda3\\lib\\site-packages (from tensorflow==1.15.3) (1.11.2)\n",
      "Requirement already satisfied: numpy<2.0,>=1.16.0 in c:\\users\\saura\\anaconda3\\lib\\site-packages (from tensorflow==1.15.3) (1.16.5)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\saura\\appdata\\roaming\\python\\python37\\site-packages (from tensorflow==1.15.3) (3.2.1)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\saura\\appdata\\roaming\\python\\python37\\site-packages (from tensorflow==1.15.3) (1.1.0)\n",
      "Requirement already satisfied: grpcio>=1.8.6 in c:\\users\\saura\\appdata\\roaming\\python\\python37\\site-packages (from tensorflow==1.15.3) (1.30.0)\n",
      "Requirement already satisfied: absl-py>=0.7.0 in c:\\users\\saura\\appdata\\roaming\\python\\python37\\site-packages (from tensorflow==1.15.3) (0.9.0)\n",
      "Requirement already satisfied: tensorflow-estimator==1.15.1 in c:\\users\\saura\\anaconda3\\lib\\site-packages (from tensorflow==1.15.3) (1.15.1)\n",
      "Requirement already satisfied: keras-preprocessing>=1.0.5 in c:\\users\\saura\\appdata\\roaming\\python\\python37\\site-packages (from tensorflow==1.15.3) (1.1.2)\n",
      "Requirement already satisfied: six>=1.10.0 in c:\\users\\saura\\anaconda3\\lib\\site-packages (from tensorflow==1.15.3) (1.12.0)\n",
      "Requirement already satisfied: wheel>=0.26; python_version >= \"3\" in c:\\users\\saura\\anaconda3\\lib\\site-packages (from tensorflow==1.15.3) (0.33.6)\n",
      "Requirement already satisfied: keras-applications>=1.0.8 in c:\\users\\saura\\anaconda3\\lib\\site-packages (from tensorflow==1.15.3) (1.0.8)\n",
      "Requirement already satisfied: gast==0.2.2 in c:\\users\\saura\\anaconda3\\lib\\site-packages (from tensorflow==1.15.3) (0.2.2)\n",
      "Requirement already satisfied: tensorboard<1.16.0,>=1.15.0 in c:\\users\\saura\\anaconda3\\lib\\site-packages (from tensorflow==1.15.3) (1.15.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.6 in c:\\users\\saura\\appdata\\roaming\\python\\python37\\site-packages (from tensorflow==1.15.3) (0.2.0)\n",
      "Requirement already satisfied: protobuf>=3.6.1 in c:\\users\\saura\\anaconda3\\lib\\site-packages (from tensorflow==1.15.3) (3.12.2)\n",
      "Requirement already satisfied: astor>=0.6.0 in c:\\users\\saura\\anaconda3\\lib\\site-packages (from tensorflow==1.15.3) (0.8.1)\n",
      "Requirement already satisfied: h5py in c:\\users\\saura\\appdata\\roaming\\python\\python37\\site-packages (from keras-applications>=1.0.8->tensorflow==1.15.3) (2.10.0)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in c:\\users\\saura\\anaconda3\\lib\\site-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.3) (41.4.0)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in c:\\users\\saura\\anaconda3\\lib\\site-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.3) (0.16.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\saura\\anaconda3\\lib\\site-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.3) (3.2.2)\n",
      "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in c:\\users\\saura\\anaconda3\\lib\\site-packages (from markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.3) (0.23)\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\users\\saura\\anaconda3\\lib\\site-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.3) (0.6.0)\n",
      "Requirement already satisfied: more-itertools in c:\\users\\saura\\anaconda3\\lib\\site-packages (from zipp>=0.5->importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.3) (7.2.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install tensorflow==1.15.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensorflow version : 2.2.0\n"
     ]
    }
   ],
   "source": [
    "print(\"Tensorflow version : {}\".format(tf.__version__))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load libraries\n",
    "\n",
    "from __future__ import print_function\n",
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "\n",
    "# set the environment path to find Recommenders\n",
    "import sys\n",
    "sys.path.append(\"../../\")\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "%matplotlib inline\n",
    "\n",
    "import papermill as pm\n",
    "\n",
    "from reco_utils.recommender.rbm.rbm import RBM\n",
    "from reco_utils.dataset.python_splitters import numpy_stratified_split\n",
    "from reco_utils.dataset.sparse import AffinityMatrix\n",
    "\n",
    "\n",
    "from reco_utils.dataset import movielens\n",
    "from reco_utils.evaluation.python_evaluation import map_at_k, ndcg_at_k, precision_at_k, recall_at_k\n",
    "\n",
    "#For interactive mode only\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "print(\"System version: {}\".format(sys.version))\n",
    "print(\"Pandas version: {}\".format(pd.__version__))\n",
    "print(\"Tensorflow version : {}\".format(tf.__version__))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select MovieLens data size: 100k, 1m, 10m, or 20m\n",
    "MOVIELENS_DATA_SIZE = '100k'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = movielens.load_pandas_df(\n",
    "    size=MOVIELENS_DATA_SIZE,\n",
    "    header=['userID','movieID','rating','timestamp']\n",
    ")\n",
    "\n",
    "# Convert to 32-bit in order to reduce memory consumption \n",
    "data.loc[:, 'rating'] = data['rating'].astype(np.int32) \n",
    "\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#to use standard names across the analysis \n",
    "header = {\n",
    "        \"col_user\": \"userID\",\n",
    "        \"col_item\": \"movieID\",\n",
    "        \"col_rating\": \"rating\",\n",
    "    }\n",
    "\n",
    "#instantiate the sparse matrix generation  \n",
    "am = AffinityMatrix(DF = data, **header)\n",
    "\n",
    "#obtain the sparse matrix \n",
    "X = am.gen_affinity_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtr, Xtst = numpy_stratified_split(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('train matrix size', Xtr.shape)\n",
    "print('test matrix size', Xtst.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import set_random_seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.set_seed()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#First we initialize the model class\n",
    "model = RBM(hidden_units= 600, training_epoch = 30, minibatch_size= 60, keep_prob=0.9,with_metrics =True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Model Fit\n",
    "train_time= model.fit(Xtr, Xtst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#number of top score elements to be recommended  \n",
    "K = 10\n",
    "\n",
    "#Model prediction on the test set Xtst. \n",
    "top_k, test_time =  model.recommend_k_items(Xtst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_k_df = am.map_back_sparse(top_k, kind = 'prediction')\n",
    "test_df = am.map_back_sparse(Xtst, kind = 'ratings')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_k_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ranking_metrics(\n",
    "    data_size,\n",
    "    data_true,\n",
    "    data_pred,\n",
    "    time_train,\n",
    "    time_test,\n",
    "    K\n",
    "):\n",
    "\n",
    "    eval_map = map_at_k(data_true, data_pred, col_user=\"userID\", col_item=\"movieID\", \n",
    "                    col_rating=\"rating\", col_prediction=\"prediction\", \n",
    "                    relevancy_method=\"top_k\", k= K)\n",
    "\n",
    "    eval_ndcg = ndcg_at_k(data_true, data_pred, col_user=\"userID\", col_item=\"movieID\", \n",
    "                      col_rating=\"rating\", col_prediction=\"prediction\", \n",
    "                      relevancy_method=\"top_k\", k= K)\n",
    "\n",
    "    eval_precision = precision_at_k(data_true, data_pred, col_user=\"userID\", col_item=\"movieID\", \n",
    "                               col_rating=\"rating\", col_prediction=\"prediction\", \n",
    "                               relevancy_method=\"top_k\", k= K)\n",
    "\n",
    "    eval_recall = recall_at_k(data_true, data_pred, col_user=\"userID\", col_item=\"movieID\", \n",
    "                          col_rating=\"rating\", col_prediction=\"prediction\", \n",
    "                          relevancy_method=\"top_k\", k= K)\n",
    "\n",
    "    \n",
    "    df_result = pd.DataFrame(\n",
    "        {   \"Dataset\": data_size,\n",
    "            \"K\": K,\n",
    "            \"MAP\": eval_map,\n",
    "            \"nDCG@k\": eval_ndcg,\n",
    "            \"Precision@k\": eval_precision,\n",
    "            \"Recall@k\": eval_recall,\n",
    "            \"Train time (s)\": time_train,\n",
    "            \"Test time (s)\": time_test\n",
    "        }, \n",
    "        index=[0]\n",
    "    )\n",
    "    \n",
    "    return df_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_100k= ranking_metrics(\n",
    "    data_size = \"mv 100k\",\n",
    "    data_true =test_df,\n",
    "    data_pred =top_k_df,\n",
    "    time_train=train_time,\n",
    "    time_test =test_time,\n",
    "    K =10)\n",
    "\n",
    "eval_100k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scrapbook as sb\n",
    "\n",
    "# Record results with papermill for tests\n",
    "sb.glue(\"map\", eval_100k['MAP'][0])\n",
    "sb.glue(\"ndcg\", eval_100k['nDCG@k'][0])\n",
    "sb.glue(\"precision\", eval_100k['Precision@k'][0])\n",
    "sb.glue(\"recall\", eval_100k['Recall@k'][0])\n",
    "sb.glue(\"train_time\", train_time)\n",
    "sb.glue(\"test_time\", test_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "# save the model to disk\n",
    "filename = 'RBM.sav'\n",
    "joblib.dump(model, filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
